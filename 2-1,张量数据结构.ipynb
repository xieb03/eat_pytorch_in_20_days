{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f01dc0a3",
   "metadata": {},
   "source": [
    "# 2-1,张量数据结构\n",
    "\n",
    "Pytorch的基本数据结构是张量Tensor。张量即多维数组。Pytorch的张量和numpy中的array很类似。\n",
    "\n",
    "本节我们主要介绍张量的数据类型、张量的维度、张量的尺寸、张量和numpy数组等基本概念。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "557c3dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__ =  2.0.1+cu118\n",
      "torchvision.__version__ =  0.15.2+cu118\n",
      "pytorch_lightning.__version__ =  2.0.2\n",
      "torchtext.__version__ =  0.15.2\n",
      "torchdata.__version__ =  0.6.1\n",
      "torchmetrics.__version__ =  0.11.4\n",
      "torchkeras.__version__ =  3.8.2\n",
      "yaml.__version__ =  6.0\n",
      "tensorflow sed random seed fail.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torchkeras\n",
    "\n",
    "#打印时间\n",
    "def printbar():\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "\n",
    "#mac系统上pytorch和matplotlib在jupyter中同时跑需要更改环境变量\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" \n",
    "from python_cgtools.utils_date import *\n",
    "from python_cgtools.utils_torch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db0902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-28 23:51:28:start.........\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print_with_time(\"start.........\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05483d16",
   "metadata": {},
   "source": [
    "```\n",
    "torch.__version__=1.10.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2a5a7",
   "metadata": {},
   "source": [
    "### 一，张量的数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2dcc21",
   "metadata": {},
   "source": [
    "张量的数据类型和numpy.array基本一一对应，但是不支持str类型。\n",
    "\n",
    "包括:\n",
    "\n",
    "torch.float64(torch.double), \n",
    "\n",
    "**torch.float32(torch.float)**, \n",
    "\n",
    "torch.float16, \n",
    "\n",
    "**torch.int64(torch.long)**, \n",
    "\n",
    "torch.int32(torch.int), \n",
    "\n",
    "torch.int16, \n",
    "\n",
    "torch.int8, \n",
    "\n",
    "torch.uint8, \n",
    "\n",
    "torch.bool\n",
    "\n",
    "一般神经网络建模使用的都是torch.float32类型。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fffeef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) torch.int64\n",
      "tensor([2.]) torch.float32\n",
      "tensor([True]) torch.bool\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "# 自动推断数据类型\n",
    "\n",
    "# tensor([1]) torch.int64\n",
    "# tensor([2.]) torch.float32\n",
    "# tensor([True]) torch.bool\n",
    "i = torch.tensor([1]);print(i,i.dtype)\n",
    "x = torch.tensor([2.0]);print(x,x.dtype)\n",
    "b = torch.tensor([True]);print(b,b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a251fa01",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] int32\n",
      "[2.] float64\n",
      "tensor([1], dtype=torch.int32) torch.int32\n",
      "tensor([2.], dtype=torch.float64) torch.float64\n"
     ]
    }
   ],
   "source": [
    "# numpy 默认类型是 int32 和 float64\n",
    "# pytorch 默认类型是 int64, float32\n",
    "\n",
    "# [1] int32\n",
    "# [2.] float64\n",
    "# tensor([1], dtype=torch.int32) torch.int32\n",
    "# tensor([2.], dtype=torch.float64) torch.float64\n",
    "i = np.array([1]);print(i,i.dtype)\n",
    "j = np.array([2.0]);print(j,j.dtype)\n",
    "\n",
    "i = torch.tensor(i);print(i,i.dtype)\n",
    "j = torch.tensor(j);print(j,j.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20c6ade",
   "metadata": {},
   "source": [
    "```\n",
    "tensor(1) torch.int64\n",
    "tensor(2.) torch.float32\n",
    "tensor(True) torch.bool\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d83c64a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1, dtype=torch.int32) torch.int32\n",
      "tensor(2., dtype=torch.float64) torch.float64\n",
      "tensor(2, dtype=torch.int32) torch.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-26717d2f600f>:7: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  y = torch.tensor(2.0,dtype = torch.int32);print(y,y.dtype)\n"
     ]
    }
   ],
   "source": [
    "# 指定数据类型\n",
    "# tensor(1, dtype=torch.int32) torch.int32\n",
    "# tensor(2., dtype=torch.float64) torch.float64\n",
    "# tensor(2, dtype=torch.int32) torch.int32\n",
    "i = torch.tensor(1,dtype = torch.int32);print(i,i.dtype)\n",
    "x = torch.tensor(2.0,dtype = torch.double);print(x,x.dtype)\n",
    "y = torch.tensor(2.0,dtype = torch.int32);print(y,y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec050d",
   "metadata": {},
   "source": [
    "```\n",
    "tensor(1, dtype=torch.int32) torch.int32\n",
    "tensor(2., dtype=torch.float64) torch.float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a12e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) torch.int64\n",
      "tensor([1], dtype=torch.int32) torch.int32\n",
      "tensor([2.]) torch.float32\n",
      "tensor([2.], dtype=torch.float64) torch.float64\n",
      "tensor([ True, False,  True, False]) torch.bool\n"
     ]
    }
   ],
   "source": [
    "# 使用特定类型构造函数\n",
    "# tensor([1]) torch.int64\n",
    "# tensor([1], dtype=torch.int32) torch.int32\n",
    "# tensor([2.]) torch.float32\n",
    "# tensor([2.], dtype=torch.float64) torch.float64\n",
    "# tensor([ True, False,  True, False]) torch.bool\n",
    "i = torch.LongTensor([1]);print(i,i.dtype)\n",
    "i = torch.IntTensor([1]);print(i,i.dtype)\n",
    "x = torch.Tensor(np.array([2.0]));print(x,x.dtype) #等价于torch.FloatTensor\n",
    "x = torch.DoubleTensor(np.array([2.0]));print(x,x.dtype)\n",
    "b = torch.BoolTensor(np.array([1,0,2,0])); print(b,b.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463f1b3",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([5], dtype=torch.int32) torch.int32\n",
    "tensor(2.) torch.float32\n",
    "tensor([ True, False,  True, False]) torch.bool\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee70926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) torch.int64\n",
      "tensor(1.) torch.float32\n",
      "tensor(1.) torch.float32\n",
      "tensor(1.) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 不同类型进行转换\n",
    "# tensor(1) torch.int64\n",
    "# tensor(1.) torch.float32\n",
    "# tensor(1.) torch.float32\n",
    "# tensor(1.) torch.float32\n",
    "i = torch.tensor(1); print(i,i.dtype)\n",
    "x = i.float(); print(x,x.dtype) #调用 float方法转换成浮点类型\n",
    "y = i.type(torch.float); print(y,y.dtype) #使用type函数转换成浮点类型\n",
    "z = i.type_as(x);print(z,z.dtype) #使用type_as方法转换成某个Tensor相同类型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909c20a9",
   "metadata": {},
   "source": [
    "```\n",
    "tensor(1) torch.int64\n",
    "tensor(1.) torch.float32\n",
    "tensor(1.) torch.float32\n",
    "tensor(1.) torch.float32\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b9bfdf",
   "metadata": {},
   "source": [
    "### 二，张量的维度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a57da",
   "metadata": {},
   "source": [
    "不同类型的数据可以用不同维度(dimension)的张量来表示。\n",
    "\n",
    "标量为0维张量，向量为1维张量，矩阵为2维张量。\n",
    "\n",
    "彩色图像有rgb三个通道，可以表示为3维张量。\n",
    "\n",
    "视频还有时间维，可以表示为4维张量。\n",
    "\n",
    "可以简单地总结为：有几层中括号，就是多少维的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296d79bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "0\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# tensor(True)\n",
    "# 0\n",
    "# torch.Size([])\n",
    "scalar = torch.tensor(True)\n",
    "print(scalar)\n",
    "print(scalar.dim())  # 标量，0维张量\n",
    "print(scalar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd89cca1",
   "metadata": {},
   "source": [
    "```\n",
    "tensor(True)\n",
    "0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7c98c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# tensor([1., 2., 3., 4.])\n",
    "# 1\n",
    "vector = torch.tensor([1.0,2.0,3.0,4.0]) #向量，1维张量\n",
    "print(vector)\n",
    "print(vector.dim())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3008240",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([1., 2., 3., 4.])\n",
    "1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95daefe1",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# tensor([[1., 2.],\n",
    "#         [3., 4.]])\n",
    "# 2\n",
    "matrix = torch.tensor([[1.0,2.0],[3.0,4.0]]) #矩阵, 2维张量\n",
    "print(matrix)\n",
    "print(matrix.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4674fd",
   "metadata": {},
   "source": [
    "```\n",
    "matrix = torch.tensor([[1.0,2.0],[3.0,4.0]]) #矩阵, 2维张量\n",
    "print(matrix)\n",
    "print(matrix.dim())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7203de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# tensor([[[1., 2.],\n",
    "#          [3., 4.]],\n",
    "\n",
    "#         [[5., 6.],\n",
    "#          [7., 8.]]])\n",
    "# 3\n",
    "tensor3 = torch.tensor([[[1.0,2.0],[3.0,4.0]],[[5.0,6.0],[7.0,8.0]]])  # 3维张量\n",
    "print(tensor3)\n",
    "print(tensor3.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5204abc",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[[1., 2.],\n",
    "         [3., 4.]],\n",
    "\n",
    "        [[5., 6.],\n",
    "         [7., 8.]]])\n",
    "3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37f98443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1.],\n",
      "          [2., 2.]],\n",
      "\n",
      "         [[3., 3.],\n",
      "          [4., 4.]]],\n",
      "\n",
      "\n",
      "        [[[5., 5.],\n",
      "          [6., 6.]],\n",
      "\n",
      "         [[7., 7.],\n",
      "          [8., 8.]]]])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# tensor([[[[1., 1.],\n",
    "#           [2., 2.]],\n",
    "\n",
    "#          [[3., 3.],\n",
    "#           [4., 4.]]],\n",
    "\n",
    "\n",
    "#         [[[5., 5.],\n",
    "#           [6., 6.]],\n",
    "\n",
    "#          [[7., 7.],\n",
    "#           [8., 8.]]]])\n",
    "# 4\n",
    "tensor4 = torch.tensor([[[[1.0,1.0],[2.0,2.0]],[[3.0,3.0],[4.0,4.0]]],\n",
    "                        [[[5.0,5.0],[6.0,6.0]],[[7.0,7.0],[8.0,8.0]]]])  # 4维张量\n",
    "print(tensor4)\n",
    "print(tensor4.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cdadc0",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[[[1., 1.],\n",
    "          [2., 2.]],\n",
    "\n",
    "         [[3., 3.],\n",
    "          [4., 4.]]],\n",
    "\n",
    "\n",
    "        [[[5., 5.],\n",
    "          [6., 6.]],\n",
    "\n",
    "         [[7., 7.],\n",
    "          [8., 8.]]]])\n",
    "4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef1ac8",
   "metadata": {},
   "source": [
    "### 三，张量的尺寸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e3a65e",
   "metadata": {},
   "source": [
    "可以使用 shape属性或者 size()方法查看张量在每一维的长度.\n",
    "\n",
    "可以使用view方法改变张量的尺寸。\n",
    "\n",
    "如果view方法改变尺寸失败，可以使用reshape方法."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d118c92",
   "metadata": {},
   "source": [
    "**torch的view()与reshape()方法都可以用来重塑tensor的shape，\n",
    "区别就是使用的条件不一样。view()方法只适用于满足连续性条件的tensor，并且该操作不会开辟新的内存空间，\n",
    "只是产生了对原存储空间的一个新别称和引用，返回值是视图。\n",
    "而reshape()方法的返回值既可以是视图，也可以是副本，当满足连续性条件时返回view，否则返回副本\n",
    "[ 此时等价于先调用contiguous()方法在使用view() ]。因此当不确能否使用view时，可以使用reshape。\n",
    "如果只是想简单地重塑一个tensor的shape，那么就是用reshape，\n",
    "但是如果需要考虑内存的开销而且要确保重塑后的tensor与之前的tensor共享存储空间，那就使用view()。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b6e583",
   "metadata": {},
   "source": [
    "**为什么没把view废除那？最近偶然看到了些资料，又想起了这个问题，觉得有以下原因：\n",
    "1、在PyTorch不同版本的更新过程中，view先于reshape方法出现，后来出现了鲁棒性更好的reshape方法，但view方法并没因此废除。其实不止PyTorch，其他一些框架或语言比如OpenCV也有类似的操作。\n",
    "2、view的存在可以显示地表示对这个tensor的操作只能是视图操作而非拷贝操作。这对于代码的可读性以及后续可能的bug的查找比较友好。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c31794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# torch.Size([])\n",
    "# torch.Size([])\n",
    "scalar = torch.tensor(True)\n",
    "print(scalar.size())\n",
    "print(scalar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544428df",
   "metadata": {},
   "source": [
    "```\n",
    "torch.Size([])\n",
    "torch.Size([4])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b95eecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# torch.Size([4])\n",
    "# torch.Size([4])\n",
    "vector = torch.tensor([1.0,2.0,3.0,4.0])\n",
    "print(vector.size())\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0af434",
   "metadata": {},
   "source": [
    "```\n",
    "torch.Size([4])\n",
    "torch.Size([4])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6e2ac42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# torch.Size([4])\n",
    "# torch.Size([2, 2])\n",
    "matrix = torch.tensor([[1.0,2.0],[3.0,4.0]])\n",
    "print(vector.size())\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6419a0",
   "metadata": {},
   "source": [
    "```\n",
    "torch.Size([2, 2])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20adf33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "torch.Size([12])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "torch.Size([3, 4])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# 使用view可以改变张量尺寸\n",
    "\n",
    "# tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
    "# torch.Size([12])\n",
    "# tensor([[ 0,  1,  2,  3],\n",
    "#         [ 4,  5,  6,  7],\n",
    "#         [ 8,  9, 10, 11]])\n",
    "# torch.Size([3, 4])\n",
    "# tensor([[ 0,  1,  2],\n",
    "#         [ 3,  4,  5],\n",
    "#         [ 6,  7,  8],\n",
    "#         [ 9, 10, 11]])\n",
    "# torch.Size([4, 3])\n",
    "vector = torch.arange(0,12)\n",
    "print(vector)\n",
    "print(vector.shape)\n",
    "\n",
    "matrix34 = vector.view(3,4)\n",
    "print(matrix34)\n",
    "print(matrix34.shape)\n",
    "\n",
    "matrix43 = vector.view(4,-1) #-1表示该位置长度由程序自动推断\n",
    "print(matrix43)\n",
    "print(matrix43.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f3d2a0",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
    "torch.Size([12])\n",
    "tensor([[ 0,  1,  2,  3],\n",
    "        [ 4,  5,  6,  7],\n",
    "        [ 8,  9, 10, 11]])\n",
    "torch.Size([3, 4])\n",
    "tensor([[ 0,  1,  2],\n",
    "        [ 3,  4,  5],\n",
    "        [ 6,  7,  8],\n",
    "        [ 9, 10, 11]])\n",
    "torch.Size([4, 3])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2c30217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n",
      "torch.Size([2, 6])\n",
      "False\n",
      "tensor([[ 0,  6,  1,  7],\n",
      "        [ 2,  8,  3,  9],\n",
      "        [ 4, 10,  5, 11]])\n"
     ]
    }
   ],
   "source": [
    "# 有些操作会让张量存储结构扭曲，直接使用view会失败，可以用reshape方法\n",
    "\n",
    "# tensor([[ 0,  1,  2,  3,  4,  5],\n",
    "#         [ 6,  7,  8,  9, 10, 11]])\n",
    "# torch.Size([2, 6])\n",
    "# False\n",
    "# tensor([[ 0,  6,  1,  7],\n",
    "#         [ 2,  8,  3,  9],\n",
    "#         [ 4, 10,  5, 11]])\n",
    "\n",
    "matrix26 = torch.arange(0,12).view(2,6)\n",
    "print(matrix26)\n",
    "print(matrix26.shape)\n",
    "\n",
    "# 转置操作让张量存储结构扭曲\n",
    "matrix62 = matrix26.t()\n",
    "print(matrix62.is_contiguous())\n",
    "\n",
    "\n",
    "# 直接使用view方法会失败，可以使用reshape方法\n",
    "#matrix34 = matrix62.view(3,4) #error!\n",
    "matrix34 = matrix62.reshape(3,4) #等价于matrix34 = matrix62.contiguous().view(3,4)\n",
    "print(matrix34)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08373aa1",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[ 0,  1,  2,  3,  4,  5],\n",
    "        [ 6,  7,  8,  9, 10, 11]])\n",
    "torch.Size([2, 6])\n",
    "False\n",
    "tensor([[ 0,  6,  1,  7],\n",
    "        [ 2,  8,  3,  9],\n",
    "        [ 4, 10,  5, 11]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f407e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1a78a18",
   "metadata": {},
   "source": [
    "### 四，张量和numpy数组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beb043e",
   "metadata": {},
   "source": [
    "可以用numpy方法从Tensor得到numpy数组，也可以用torch.from_numpy从numpy数组得到Tensor。\n",
    "\n",
    "这两种方法关联的Tensor和numpy数组是共享数据内存的。\n",
    "\n",
    "如果改变其中一个，另外一个的值也会发生改变。\n",
    "\n",
    "如果有需要，可以用张量的clone方法拷贝张量，中断这种关联。\n",
    "\n",
    "此外，还可以使用item方法从标量张量得到对应的Python数值。\n",
    "\n",
    "使用tolist方法从张量得到对应的Python数值列表。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d04284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fb0fb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before add 1:\n",
      "[0. 0. 0.]\n",
      "tensor([0., 0., 0.], dtype=torch.float64)\n",
      "\n",
      "after add 1:\n",
      "[1. 1. 1.]\n",
      "tensor([1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#torch.from_numpy函数从numpy数组得到Tensor\n",
    "\n",
    "arr = np.zeros(3)\n",
    "tensor = torch.from_numpy(arr)\n",
    "print(\"before add 1:\")\n",
    "print(arr)\n",
    "print(tensor)\n",
    "\n",
    "print(\"\\nafter add 1:\")\n",
    "np.add(arr,1, out = arr) #给 arr增加1，tensor也随之改变\n",
    "print(arr)\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c1fa55",
   "metadata": {},
   "source": [
    "```\n",
    "before add 1:\n",
    "[0. 0. 0.]\n",
    "tensor([0., 0., 0.], dtype=torch.float64)\n",
    "\n",
    "after add 1:\n",
    "[1. 1. 1.]\n",
    "tensor([1., 1., 1.], dtype=torch.float64)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6b4e316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before add 1:\n",
      "tensor([0., 0., 0.])\n",
      "[0. 0. 0.]\n",
      "\n",
      "after add 1:\n",
      "tensor([1., 1., 1.])\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# numpy方法从Tensor得到numpy数组\n",
    "\n",
    "tensor = torch.zeros(3)\n",
    "arr = tensor.numpy()\n",
    "print(\"before add 1:\")\n",
    "print(tensor)\n",
    "print(arr)\n",
    "\n",
    "print(\"\\nafter add 1:\")\n",
    "\n",
    "#使用带下划线的方法表示计算结果会返回给调用 张量\n",
    "tensor.add_(1) #给 tensor增加1，arr也随之改变 \n",
    "#或： torch.add(tensor,1,out = tensor)\n",
    "print(tensor)\n",
    "print(arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd229d",
   "metadata": {},
   "source": [
    "```\n",
    "before add 1:\n",
    "tensor([0., 0., 0.])\n",
    "[0. 0. 0.]\n",
    "\n",
    "after add 1:\n",
    "tensor([1., 1., 1.])\n",
    "[1. 1. 1.]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a78d00c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before add 1:\n",
      "tensor([0., 0., 0.])\n",
      "[0. 0. 0.]\n",
      "\n",
      "after add 1:\n",
      "tensor([1., 1., 1.])\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 可以用clone() 方法拷贝张量，中断这种关联\n",
    "\n",
    "tensor = torch.zeros(3)\n",
    "\n",
    "#使用clone方法拷贝张量, 拷贝后的张量和原始张量内存独立\n",
    "# before add 1:\n",
    "# tensor([0., 0., 0.])\n",
    "# [0. 0. 0.]\n",
    "\n",
    "# after add 1:\n",
    "# tensor([1., 1., 1.])\n",
    "# [0. 0. 0.]\n",
    "arr = tensor.clone().numpy() # 也可以使用tensor.data.numpy()\n",
    "print(\"before add 1:\")\n",
    "print(tensor)\n",
    "print(arr)\n",
    "\n",
    "print(\"\\nafter add 1:\")\n",
    "\n",
    "#使用 带下划线的方法表示计算结果会返回给调用 张量\n",
    "tensor.add_(1) #给 tensor增加1，arr不再随之改变\n",
    "print(tensor)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad81d313",
   "metadata": {},
   "source": [
    "```\n",
    "before add 1:\n",
    "tensor([0., 0., 0.])\n",
    "[0. 0. 0.]\n",
    "\n",
    "after add 1:\n",
    "tensor([1., 1., 1.])\n",
    "[0. 0. 0.]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58ef1fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "<class 'float'>\n",
      "[[0.09181702136993408, 0.47938060760498047], [0.8105512857437134, 0.015107154846191406]]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# item方法和tolist方法可以将张量转换成Python数值和数值列表\n",
    "scalar = torch.tensor(1.0)\n",
    "s = scalar.item()\n",
    "print(s)\n",
    "print(type(s))\n",
    "\n",
    "tensor = torch.rand(2,2)\n",
    "t = tensor.tolist()\n",
    "print(t)\n",
    "print(type(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b041277",
   "metadata": {},
   "source": [
    "```\n",
    "1.0\n",
    "<class 'float'>\n",
    "[[0.8211846351623535, 0.20020723342895508], [0.011571824550628662, 0.2906131148338318]]\n",
    "<class 'list'>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d94c77b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 2 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-090de5b0c480>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# RuntimeError: a Tensor with 2 elements cannot be converted to Scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 只有 scalar 可以使用 item(),转化为 python 数值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 2 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "# RuntimeError: a Tensor with 2 elements cannot be converted to Scalar\n",
    "# 只有 scalar 可以使用 item(),转化为 python 数值\n",
    "torch.tensor([1.0, 2.0]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e68eaf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe52e4a",
   "metadata": {},
   "source": [
    "**如果本书对你有所帮助，想鼓励一下作者，记得给本项目加一颗星星star⭐️，并分享给你的朋友们喔😊!** \n",
    "\n",
    "如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n",
    "\n",
    "也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n",
    "\n",
    "![算法美食屋logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
