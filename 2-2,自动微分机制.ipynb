{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b1c09e",
   "metadata": {},
   "source": [
    "# 2-2,è‡ªåŠ¨å¾®åˆ†æœºåˆ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2a272",
   "metadata": {},
   "source": [
    "ç¥ç»ç½‘ç»œé€šå¸¸ä¾èµ–åå‘ä¼ æ’­æ±‚æ¢¯åº¦æ¥æ›´æ–°ç½‘ç»œå‚æ•°ï¼Œæ±‚æ¢¯åº¦è¿‡ç¨‹é€šå¸¸æ˜¯ä¸€ä»¶éå¸¸å¤æ‚è€Œå®¹æ˜“å‡ºé”™çš„äº‹æƒ…ã€‚\n",
    "\n",
    "è€Œæ·±åº¦å­¦ä¹ æ¡†æ¶å¯ä»¥å¸®åŠ©æˆ‘ä»¬è‡ªåŠ¨åœ°å®Œæˆè¿™ç§æ±‚æ¢¯åº¦è¿ç®—ã€‚\n",
    "\n",
    "Pytorchä¸€èˆ¬é€šè¿‡åå‘ä¼ æ’­ backward æ–¹æ³• å®ç°è¿™ç§æ±‚æ¢¯åº¦è®¡ç®—ã€‚è¯¥æ–¹æ³•æ±‚å¾—çš„æ¢¯åº¦å°†å­˜åœ¨å¯¹åº”è‡ªå˜é‡å¼ é‡çš„gradå±æ€§ä¸‹ã€‚\n",
    "\n",
    "**é™¤æ­¤ä¹‹å¤–ï¼Œä¹Ÿèƒ½å¤Ÿè°ƒç”¨torch.autograd.grad å‡½æ•°æ¥å®ç°æ±‚æ¢¯åº¦è®¡ç®—ï¼Œä½†ç”¨çš„æ¯”è¾ƒå°‘ï¼Œä¸€èˆ¬ç”¨æ¥æ±‚é«˜é˜¶å¯¼æ•°ã€‚**\n",
    "\n",
    "è¿™å°±æ˜¯Pytorchçš„è‡ªåŠ¨å¾®åˆ†æœºåˆ¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663ac7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__ =  2.0.1+cu118\n",
      "torchvision.__version__ =  0.15.2+cu118\n",
      "pytorch_lightning.__version__ =  2.0.2\n",
      "torchtext.__version__ =  0.15.2\n",
      "torchdata.__version__ =  0.6.1\n",
      "torchmetrics.__version__ =  0.11.4\n",
      "torchkeras.__version__ =  3.8.2\n",
      "yaml.__version__ =  6.0\n",
      "tensorflow sed random seed fail.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torchkeras\n",
    "\n",
    "#æ‰“å°æ—¶é—´\n",
    "def printbar():\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "\n",
    "#macç³»ç»Ÿä¸Špytorchå’Œmatplotlibåœ¨jupyterä¸­åŒæ—¶è·‘éœ€è¦æ›´æ”¹ç¯å¢ƒå˜é‡\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" \n",
    "from python_cgtools.utils_date import *\n",
    "from python_cgtools.utils_torch import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e72ea02",
   "metadata": {},
   "source": [
    "```\n",
    "torch.__version__=1.10.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ef2634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-29 00:42:39:start.........\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print_with_time(\"start.........\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80820ba",
   "metadata": {},
   "source": [
    "### ä¸€ï¼Œåˆ©ç”¨backwardæ–¹æ³•æ±‚å¯¼æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c211749b",
   "metadata": {},
   "source": [
    "backward æ–¹æ³•é€šå¸¸åœ¨ä¸€ä¸ªæ ‡é‡å¼ é‡ä¸Šè°ƒç”¨ï¼Œè¯¥æ–¹æ³•æ±‚å¾—çš„æ¢¯åº¦å°†å­˜åœ¨å¯¹åº”è‡ªå˜é‡å¼ é‡çš„gradå±æ€§ä¸‹ã€‚\n",
    "\n",
    "å¦‚æœè°ƒç”¨çš„å¼ é‡éæ ‡é‡ï¼Œåˆ™è¦ä¼ å…¥ä¸€ä¸ªå’Œå®ƒåŒå½¢çŠ¶ çš„gradientå‚æ•°å¼ é‡ã€‚\n",
    "\n",
    "ç›¸å½“äºç”¨è¯¥gradientå‚æ•°å¼ é‡ä¸è°ƒç”¨å¼ é‡ä½œå‘é‡ç‚¹ä¹˜ï¼Œå¾—åˆ°çš„æ ‡é‡ç»“æœå†åå‘ä¼ æ’­ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43160576",
   "metadata": {},
   "source": [
    "**1, æ ‡é‡çš„åå‘ä¼ æ’­**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b528ce63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "# f(x) = a*x**2 + b*x + cçš„å¯¼æ•°\n",
    "\n",
    "x = torch.tensor(0.0,requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼\n",
    "a = torch.tensor(1.0)\n",
    "b = torch.tensor(-2.0)\n",
    "c = torch.tensor(1.0)\n",
    "y = a*torch.pow(x,2) + b*x + c \n",
    "\n",
    "y.backward()\n",
    "dy_dx = x.grad\n",
    "# tensor(-2.)\n",
    "print(dy_dx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b49a0",
   "metadata": {},
   "source": [
    "```\n",
    "tensor(-2.)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee7aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "x = torch.tensor([0.0, 0.0],requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼\n",
    "y = torch.pow(x,2)\n",
    "\n",
    "# RuntimeError: grad can be implicitly created only for scalar outputs\n",
    "# æ±‚å¯¼é»˜è®¤åªèƒ½å¯¹æ ‡é‡æ¥æ±‚ï¼Œä¸€èˆ¬æ¨¡å‹çš„ loss éƒ½æ˜¯æ ‡é‡\n",
    "# y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8f8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "x = torch.tensor([0.0],requires_grad = False)\n",
    "y = torch.pow(x,2)\n",
    "\n",
    "# RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
    "# èƒ½æ±‚å¯¼è¦æ±‚åŒ…å«è‡ªå˜é‡ï¼Œå³ requires_grad=True çš„é‡\n",
    "# y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09f3917",
   "metadata": {},
   "source": [
    "**2, éæ ‡é‡çš„åå‘ä¼ æ’­**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08b055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([[0., 0.],\n",
      "        [1., 2.]], requires_grad=True)\n",
      "y:\n",
      " tensor([[1., 1.],\n",
      "        [0., 1.]], grad_fn=<AddBackward0>)\n",
      "x_grad:\n",
      " tensor([[-2., -2.],\n",
      "        [ 0.,  2.]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "# f(x) = a*x**2 + b*x + c\n",
    "\n",
    "x = torch.tensor([[0.0,0.0],[1.0,2.0]],requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼\n",
    "a = torch.tensor(1.0)\n",
    "b = torch.tensor(-2.0)\n",
    "c = torch.tensor(1.0)\n",
    "# [0, 0, 1, 4] - [0, 0, 2, 4] + 1 = [1, 1, 0, 1]\n",
    "y = a*torch.pow(x,2) + b*x + c \n",
    "\n",
    "gradient = torch.tensor([[1.0,1.0],[1.0,1.0]])\n",
    "\n",
    "# x:\n",
    "#  tensor([[0., 0.],\n",
    "#         [1., 2.]], requires_grad=True)\n",
    "# y:\n",
    "#  tensor([[1., 1.],\n",
    "#         [0., 1.]], grad_fn=<AddBackward0>)\n",
    "# x_grad:\n",
    "#  tensor([[-2., -2.],\n",
    "#         [ 0.,  2.]])\n",
    "print(\"x:\\n\",x)\n",
    "print(\"y:\\n\",y)\n",
    "y.backward(gradient = gradient)\n",
    "x_grad = x.grad\n",
    "print(\"x_grad:\\n\",x_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1edbaa3",
   "metadata": {},
   "source": [
    "```\n",
    "x:\n",
    " tensor([[0., 0.],\n",
    "        [1., 2.]], requires_grad=True)\n",
    "y:\n",
    " tensor([[1., 1.],\n",
    "        [0., 1.]], grad_fn=<AddBackward0>)\n",
    "x_grad:\n",
    " tensor([[-2., -2.],\n",
    "        [ 0.,  2.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53911b0f",
   "metadata": {},
   "source": [
    "**3, éæ ‡é‡çš„åå‘ä¼ æ’­å¯ä»¥ç”¨æ ‡é‡çš„åå‘ä¼ æ’­å®ç°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4323b96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[0., 0.],\n",
      "        [1., 2.]], requires_grad=True)\n",
      "y: tensor([[1., 1.],\n",
      "        [0., 1.]], grad_fn=<AddBackward0>)\n",
      "x_grad:\n",
      " tensor([[-2., -2.],\n",
      "        [ 0.,  2.]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "# f(x) = a*x**2 + b*x + c\n",
    "\n",
    "x = torch.tensor([[0.0,0.0],[1.0,2.0]],requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼\n",
    "a = torch.tensor(1.0)\n",
    "b = torch.tensor(-2.0)\n",
    "c = torch.tensor(1.0)\n",
    "y = a*torch.pow(x,2) + b*x + c \n",
    "\n",
    "gradient = torch.tensor([[1.0,1.0],[1.0,1.0]])\n",
    "# å°†ç»“æœå˜æˆä¸€ä¸ªæ ‡é‡ï¼Œå¦‚æœ gradient éƒ½æ˜¯å…ƒç´ 1ï¼Œç›¸å½“äºå°†å„ä¸ªåˆ†é‡ç›¸åŠ ï¼Œå¯¹äºæ­¤ä¾‹æ¥è¯´ï¼Œx çš„åˆ†é‡ä¹‹é—´æ²¡æœ‰è€¦åˆï¼Œå› æ­¤ç»“æœç­‰ä»·äºæ¯ä¸ªåˆ†é‡ç‹¬ç«‹æ±‚å¯¼\n",
    "# æ³¨æ„æ˜¯åå¯¼\n",
    "# z = (2a^2 - 2a + 1) + (2b^2 - 2b + 1) + (2c^2 - 2c + 1) + (2d^2 - 2d + 1)\n",
    "# âˆ‚z/âˆ‚x_0 = 2a - 2 = -2\n",
    "# âˆ‚z/âˆ‚x_1 = 2b - 2 = -2\n",
    "# âˆ‚z/âˆ‚x_2 = 2c - 2 = 0\n",
    "# âˆ‚z/âˆ‚x_3 = 2d - 2 = 2\n",
    "z = torch.sum(y*gradient)\n",
    "\n",
    "# x: tensor([[0., 0.],\n",
    "#         [1., 2.]], requires_grad=True)\n",
    "# y: tensor([[1., 1.],\n",
    "#         [0., 1.]], grad_fn=<AddBackward0>)\n",
    "# x_grad:\n",
    "#  tensor([[-2., -2.],\n",
    "#         [ 0.,  2.]])\n",
    "print(\"x:\",x)\n",
    "print(\"y:\",y)\n",
    "z.backward()\n",
    "x_grad = x.grad\n",
    "print(\"x_grad:\\n\",x_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d771601",
   "metadata": {},
   "source": [
    "```\n",
    "x: tensor([[0., 0.],\n",
    "        [1., 2.]], requires_grad=True)\n",
    "y: tensor([[1., 1.],\n",
    "        [0., 1.]], grad_fn=<AddBackward0>)\n",
    "x_grad:\n",
    " tensor([[-2., -2.],\n",
    "        [ 0.,  2.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0b7f889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[0., 0.],\n",
      "        [1., 2.]], requires_grad=True)\n",
      "y: tensor([[0., 0.],\n",
      "        [2., 4.]], grad_fn=<MmBackward0>)\n",
      "x_grad:\n",
      " tensor([[1., 4.],\n",
      "        [2., 5.]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "# f(x) = a*x**2 + b*x + c\n",
    "\n",
    "x = torch.tensor([[0.0,0.0],[1.0,2.0]],requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼\n",
    "y = torch.matmul(x, x)\n",
    "\n",
    "gradient = torch.tensor([[1.0,1.0],[1.0,1.0]])\n",
    "# å¦‚æœæ ‡é‡å¯¹äº x çš„åˆ†é‡å¹¶ä¸ç‹¬ç«‹ï¼Œå³åˆ†é‡ä¹‹é—´æœ‰äº¤å‰ï¼Œé‚£ä¹ˆç»“æœä¼šæ›´å¤æ‚ä¸€äº›\n",
    "# z = [[a, b], [c, d]] * [[a, b], [c, d]] = (a^2 + bc) + (ab + bd) + (ca + dc) + (cb + d^2) = a^2 + ab + ac + 2bc + bd + cd + d^2\n",
    "# a = 0, b = 0, c = 1, d = 2\n",
    "# âˆ‚z/âˆ‚a = 2a + b + c = 1\n",
    "# âˆ‚z/âˆ‚b = a + 2c + d = 4\n",
    "# âˆ‚z/âˆ‚c = a + 2b + d = 2\n",
    "# âˆ‚z/âˆ‚d = b + c + 2d = 5\n",
    "z = torch.sum(y*gradient)\n",
    "\n",
    "# x: tensor([[0., 0.],\n",
    "#         [1., 2.]], requires_grad=True)\n",
    "# y: tensor([[0., 0.],\n",
    "#         [2., 4.]], grad_fn=<MmBackward0>)\n",
    "# x_grad:\n",
    "#  tensor([[1., 4.],\n",
    "#         [2., 5.]])\n",
    "print(\"x:\",x)\n",
    "print(\"y:\",y)\n",
    "z.backward()\n",
    "x_grad = x.grad\n",
    "print(\"x_grad:\\n\",x_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb1d1421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[0., 0.],\n",
      "        [1., 2.]], requires_grad=True)\n",
      "y: tensor([[0., 0.],\n",
      "        [2., 4.]], grad_fn=<MmBackward0>)\n",
      "x_grad:\n",
      " tensor([[ 2.,  8.],\n",
      "        [ 4., 10.]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "# f(x) = a*x**2 + b*x + c\n",
    "\n",
    "x = torch.tensor([[0.0,0.0],[1.0,2.0]],requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼\n",
    "y = torch.matmul(x, x)\n",
    "\n",
    "gradient = torch.tensor([[1.0,1.0],[1.0,1.0]])\n",
    "# å¦‚æœæ ‡é‡å¯¹äº x çš„åˆ†é‡å¹¶ä¸ç‹¬ç«‹ï¼Œå³åˆ†é‡ä¹‹é—´æœ‰äº¤å‰ï¼Œé‚£ä¹ˆç»“æœä¼šæ›´å¤æ‚ä¸€äº›\n",
    "# z = [[a, b], [c, d]] * [[a, b], [c, d]] = (a^2 + bc) + (ab + bd) + (ca + dc) + (cb + d^2) = a^2 + ab + ac + 2bc + bd + cd + d^2\n",
    "# a = 0, b = 0, c = 1, d = 2\n",
    "# âˆ‚z/âˆ‚a = 2a + b + c = 1\n",
    "# âˆ‚z/âˆ‚b = a + 2c + d = 4\n",
    "# âˆ‚z/âˆ‚c = a + 2b + d = 2\n",
    "# âˆ‚z/âˆ‚d = b + c + 2d = 5\n",
    "z = torch.sum(y*gradient)\n",
    "\n",
    "# x: tensor([[0., 0.],\n",
    "#         [1., 2.]], requires_grad=True)\n",
    "# y: tensor([[0., 0.],\n",
    "#         [2., 4.]], grad_fn=<MmBackward0>)\n",
    "# x_grad:\n",
    "#  tensor([[ 2.,  8.],\n",
    "#         [ 4., 10.]])\n",
    "print(\"x:\",x)\n",
    "print(\"y:\",y)\n",
    "# å¦‚æœè¦å¤šæ¬¡æ±‚æ¢¯åº¦ï¼Œé¦–å…ˆè¦æŠŠ retain_graph è®¾ç½®æˆ Trueï¼Œç„¶å pytorch é»˜è®¤ä¼šæŠŠå¤šæ¬¡æ±‚æ¢¯åº¦çš„ç»“æœåŠ å’Œ\n",
    "# å¯¹äºæ­¤ä¾‹å¯ä»¥çœ‹åˆ°æ¢¯åº¦ç»“æœä¹˜ä»¥äº† 2\n",
    "z.backward(retain_graph=True)\n",
    "z.backward()\n",
    "x_grad = x.grad\n",
    "print(\"x_grad:\\n\",x_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad40b01",
   "metadata": {},
   "source": [
    "### äºŒï¼Œåˆ©ç”¨autograd.gradæ–¹æ³•æ±‚å¯¼æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53328d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.)\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "# f(x) = a*x**2 + b*x + cçš„å¯¼æ•°\n",
    "\n",
    "x = torch.tensor(0.0,requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼\n",
    "a = torch.tensor(1.0)\n",
    "b = torch.tensor(-2.0)\n",
    "c = torch.tensor(1.0)\n",
    "y = a*torch.pow(x,2) + b*x + c\n",
    "\n",
    "\n",
    "# create_graph è®¾ç½®ä¸º True å°†å…è®¸åˆ›å»ºæ›´é«˜é˜¶çš„å¯¼æ•° \n",
    "# dy / dx = 2x + b = -2\n",
    "dy_dx = torch.autograd.grad(y,x,create_graph=True)[0]\n",
    "# tensor(-2.)\n",
    "print(dy_dx.data)\n",
    "\n",
    "# æ±‚äºŒé˜¶å¯¼æ•°\n",
    "# dy2/dx2 = d(2x +b) / dx = 2\n",
    "dy2_dx2 = torch.autograd.grad(dy_dx,x)[0] \n",
    "# tensor(2.)\n",
    "print(dy2_dx2.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a93cf05",
   "metadata": {},
   "source": [
    "```\n",
    "tensor(-2.)\n",
    "tensor(2.)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "320ddde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.) tensor(1.)\n",
      "tensor(3.) tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "x1 = torch.tensor(1.0,requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼\n",
    "x2 = torch.tensor(2.0,requires_grad = True)\n",
    "\n",
    "y1 = x1*x2\n",
    "y2 = x1+x2\n",
    "\n",
    "\n",
    "# å…è®¸åŒæ—¶å¯¹å¤šä¸ªè‡ªå˜é‡æ±‚å¯¼æ•°\n",
    "# dy1/dx1 = x2 = 2\n",
    "# dy1/dx2 = 1\n",
    "# å¿…é¡»è®¾ç½® retain_graph = True,å¦åˆ™\n",
    "# Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). \n",
    "# Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). \n",
    "# Specify retain_graph=True if you need to backward through the graph a second time \n",
    "# or if you need to access saved tensors after calling backward.\n",
    "(dy1_dx1,dy1_dx2) = torch.autograd.grad(outputs=y1,inputs = [x1,x2],retain_graph = True)\n",
    "# tensor(2.) tensor(1.)\n",
    "print(dy1_dx1,dy1_dx2)\n",
    "\n",
    "# å¦‚æœæœ‰å¤šä¸ªå› å˜é‡ï¼Œç›¸å½“äºæŠŠå¤šä¸ªå› å˜é‡çš„æ¢¯åº¦ç»“æœæ±‚å’Œ\n",
    "# dy1/dx1 + dy2/dx1 = x2 + 1 = 3\n",
    "# dy1/dx2 + dy2/dx2 = x1 + 1 = 2\n",
    "(dy12_dx1,dy12_dx2) = torch.autograd.grad(outputs=[y1,y2],inputs = [x1,x2])\n",
    "print(dy12_dx1,dy12_dx2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5a169",
   "metadata": {},
   "source": [
    "```\n",
    "tensor(2.) tensor(1.)\n",
    "tensor(3.) tensor(2.)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8600f6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6169370f",
   "metadata": {},
   "source": [
    "### ä¸‰ï¼Œåˆ©ç”¨è‡ªåŠ¨å¾®åˆ†å’Œä¼˜åŒ–å™¨æ±‚æå€¼ï¼ˆä¸ä¸€å®šæ˜¯æœ€ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31648fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y= tensor(0.) ; x= tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "\n",
    "# f(x) = a*x**2 + b*x + cçš„æœ€å°å€¼\n",
    "\n",
    "x = torch.tensor(0.0,requires_grad = True) # xéœ€è¦è¢«æ±‚å¯¼\n",
    "a = torch.tensor(1.0)\n",
    "b = torch.tensor(-2.0)\n",
    "c = torch.tensor(1.0)\n",
    "\n",
    "optimizer = torch.optim.SGD(params=[x],lr = 0.01)\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    result = a*torch.pow(x,2) + b*x + c \n",
    "    return(result)\n",
    "\n",
    "# å…¶å®å°±æ˜¯æ¨¡æ‹Ÿäº†æ¢¯åº¦ä¸‹é™ï¼Œæ³¨æ„ y = f(x) æ¯æ¬¡éƒ½ä¼šç”¨æ–°çš„ x é‡æ–°è®¡ç®—ï¼Œç›¸å½“äºæ¯ä¸ª batch ç»“æŸåï¼Œè¦æ›´æ–°è¾“å…¥ï¼Œé‡æ–°ç®—æ¢¯åº¦\n",
    "x_list = list()\n",
    "y_list = list()\n",
    "grad_list = list()\n",
    "for i in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    x_list.append(x.item())\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    optimizer.step()\n",
    "#     è¦æ”¾åœ¨ optimizer.step() å‰é¢ï¼Œå¦åˆ™ x çš„å€¼ä¼šè¢«æ¢¯åº¦ä¸‹é™æ›´æ–°\n",
    "#     x_list.append(x.item())\n",
    "    y_list.append(y.item())\n",
    "    grad_list.append(x.grad.item())\n",
    "    \n",
    "print(\"y=\",f(x).data,\";\",\"x=\",x.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5cc5fd",
   "metadata": {},
   "source": [
    "```\n",
    "y= tensor(0.) ; x= tensor(1.0000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bcb0cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>grad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.960400</td>\n",
       "      <td>-1.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.922368</td>\n",
       "      <td>-1.920800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058808</td>\n",
       "      <td>0.885842</td>\n",
       "      <td>-1.882384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.077632</td>\n",
       "      <td>0.850763</td>\n",
       "      <td>-1.844736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y      grad\n",
       "0    0.000000  1.000000 -2.000000\n",
       "1    0.020000  0.960400 -1.960000\n",
       "2    0.039600  0.922368 -1.920800\n",
       "3    0.058808  0.885842 -1.882384\n",
       "4    0.077632  0.850763 -1.844736\n",
       "..        ...       ...       ...\n",
       "495  0.999955  0.000000 -0.000091\n",
       "496  0.999956  0.000000 -0.000089\n",
       "497  0.999956  0.000000 -0.000087\n",
       "498  0.999957  0.000000 -0.000085\n",
       "499  0.999958  0.000000 -0.000084\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x\ty\tgrad\n",
    "# 0\t0.020000\t1.000000\t-2.000000\n",
    "# 1\t0.039600\t0.960400\t-1.960000\n",
    "# 2\t0.058808\t0.922368\t-1.920800\n",
    "# 3\t0.077632\t0.885842\t-1.882384\n",
    "# 4\t0.096079\t0.850763\t-1.844736\n",
    "# ...\t...\t...\t...\n",
    "# 495\t0.999956\t0.000000\t-0.000091\n",
    "# 496\t0.999956\t0.000000\t-0.000089\n",
    "# 497\t0.999957\t0.000000\t-0.000087\n",
    "# 498\t0.999958\t0.000000\t-0.000085\n",
    "# 499\t0.999959\t0.000000\t-0.000084\n",
    "df = pd.DataFrame(zip(x_list, y_list, grad_list), columns=[\"x\", \"y\", \"grad\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2078a097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df7506",
   "metadata": {},
   "source": [
    "**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** \n",
    "\n",
    "å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·\"ç®—æ³•ç¾é£Ÿå±‹\"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚\n",
    "\n",
    "ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚\n",
    "\n",
    "![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
